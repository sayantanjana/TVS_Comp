# -*- coding: utf-8 -*-
"""TVS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pvLC1ddmXJ76mMCnhoRT4cOgbhBsnZp8
"""

# Commented out IPython magic to ensure Python compatibility.
import itertools
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import NullFormatter
import pandas as pd
import numpy as np
import matplotlib.ticker as ticker
from sklearn import preprocessing
import seaborn as sns
from datetime import datetime
from datetime import date

# %matplotlib inline

#pip install -U imbalanced-learn --user

tvs = pd.read_csv(r'/content/TVS.csv',low_memory=False)

tvs.head()

tvs.shape

tvs.isnull().sum()

sns.set_style('whitegrid')
fig=sns.countplot(x='V32', hue='V13', data=tvs,palette='PiYG_r')
fig.set(xlabel='defaulter=1', ylabel='count')
for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()+.07, i.get_height()+1200, str(round((i.get_height()), 2)), fontsize=12, color='black',
                rotation=0)

sns.set_style('whitegrid')
fig=sns.countplot(x='V2', hue='V13', data=tvs,palette='PuBu')
fig.set(xlabel='Bounced=1', ylabel='count')

for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()+.07, i.get_height()+1000, str(round((i.get_height()), 2)), fontsize=12, color='black',
                rotation=0)

sns.set_style('whitegrid')
fig=sns.countplot(x='V15', hue='V13', data=tvs)
fig.set(xlabel='residence', ylabel='count')

for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()+.07, i.get_height()+1000, str(round((i.get_height()), 2)), fontsize=12, color='black',
                rotation=0)

sns.set_style('whitegrid')
fig=sns.countplot(x='V10', hue='V13', data=tvs,palette='YlOrRd')
fig.set(xlabel='vehicle', ylabel='count')

for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()-.04, i.get_height()+1000, str(round((i.get_height()), 2)), fontsize=12, color='black',
                rotation=0)

sns.set_style('whitegrid')
fig=sns.countplot(x='V14', hue='V13', data=tvs,palette='BuGn')
fig.set(xlabel='employmnt', ylabel='count')

for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()+.03, i.get_height()+1000, str(round((i.get_height()), 2)), fontsize=11, color='black',
                rotation=0)

sns.set_style('whitegrid')
fig=sns.countplot(x='V31', hue='V13', data=tvs,palette='GnBu_d')
fig.set(xlabel='Tier', ylabel='count')
for i in fig.patches:
    # get_x pulls left or right; get_height pushes up or down
    fig.text(i.get_x()+.04, i.get_height()+1000, str(round((i.get_height()), 2)), fontsize=12, color='black',
                rotation=0)

tvs['V10'].value_counts()

tvs['V2'].value_counts()

tvs['V14'].value_counts()

tvs['V31'].value_counts()

tvs['V32'].value_counts()

tvs['V15'].value_counts()

tvs.isnull().sum()

sns.set_style("whitegrid") 
sns.boxplot(x = 'V13', y = 'V25', data = tvs)

tvs['V25'] = tvs['V25'].fillna((tvs['V25'].median()))

tvs=tvs.drop(['V21', 'V23','V24','V26','V27'], axis = 1)

tvs=tvs.dropna()

tvs.shape

tvs = tvs.reset_index(drop=True)

tvs=tvs.drop(['V1','V9'], axis = 1)

tvs.columns

"""## Change DOB to age"""

tvs['V16'].head()

tvs['V16'] = pd.to_datetime(tvs['V16'], errors='coerce')

now = pd.to_datetime('now')
now

tvs['V16']=(now - tvs['V16']).dt.total_seconds() / (60*60*24*365.25)

tvs['V16'].head()

"""# Dummy Creation

##  V10---Vehicle type----MC(motorcycle) as reference

## V13------Gender-----Male(1), Female(0) 

## V14------Employment-----Housewife as reference

## V15------Residence------Owned by Office as reference

## V31------Tier-----------Tier 1 as reference
"""



tvs.columns

tvs.head()

tvs['V10'].value_counts()

Vehc = pd.get_dummies(tvs['V10'],prefix='vehc',drop_first=True)

Vehc.head()

tvs['V13'].value_counts()

tvs['V13'].replace(to_replace=['MALE','FEMALE'], value=[1,0],inplace=True)

tvs['V14'].value_counts()

Emp = pd.get_dummies(tvs['V14'],prefix='emp',drop_first=True)

Emp.head()

tvs['V15'].value_counts()

Res = pd.get_dummies(tvs['V15'],prefix='res',drop_first=True)

Res.head()

tvs['V31'].value_counts()

Tier = pd.get_dummies(tvs['V31'],prefix='tier',drop_first=True)

Tier.head()

tvs = pd.concat([tvs, Vehc,Emp,Res,Tier], axis=1)

"""### V22 has all zero values"""

tvs=tvs.drop(['V10','V14','V15','V22','V31'], axis=1)

tvs.columns

"""# Feature Selection"""

feature_cols=['V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V11', 'V12', 'V13', 'V16',
       'V17', 'V18', 'V19', 'V20', 'V25', 'V28', 'V29', 'V30', 
       'vehc_MO', 'vehc_RETOP', 'vehc_SC', 'vehc_TL', 'emp_PENS', 'emp_SAL',
       'emp_SELF', 'emp_STUDENT', 'res_OWNED', 'res_RENT', 'tier_TIER 2',
       'tier_TIER 3', 'tier_TIER 4']
dept_col=['V32']
X=tvs[feature_cols]
y=tvs[dept_col]

y.columns

str_list = [] # empty list to contain columns with strings (words)
for colname, colvalue in tvs.iteritems():
    if type(colvalue[1]) == str:
         str_list.append(colname)
# Get to the numeric columns by inversion            
num_list = tvs.columns.difference(str_list) 
# Create Dataframe containing only numerical features
house_num = tvs[num_list]
f, ax = plt.subplots(figsize=(20, 16))
plt.title('Pearson Correlation of features')
# Draw the heatmap using seaborn
#sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap="PuBuGn", linecolor='k', annot=True)
sns.heatmap(house_num.astype(float).corr(),linewidths=0.30,vmax=1.1, square=True, cmap="cubehelix", linecolor='k', annot=True)

"""### SMOTE"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix,accuracy_score

from imblearn.over_sampling import SMOTE
os = SMOTE(random_state=0)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
columns = X_train.columns
os_data_X,os_data_y=os.fit_sample(X_train, y_train)
os_data_X = pd.DataFrame(data=os_data_X,columns=columns )
os_data_y= pd.DataFrame(data=os_data_y,columns=['V32'])
# we can Check the numbers of our data
print("length of oversampled data is ",len(os_data_X))
print("Number of no subscription in oversampled data",len(os_data_y[os_data_y['V32']==0]))
print("Number of subscription",len(os_data_y[os_data_y['V32']==1]))
print("Proportion of no subscription data in oversampled data is ",len(os_data_y[os_data_y['V32']==0])/len(os_data_X))
print("Proportion of subscription data in oversampled data is ",len(os_data_y[os_data_y['V32']==1])/len(os_data_X))

feature_cols=['V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V11', 'V12', 'V13', 'V16',
       'V17', 'V18', 'V19', 'V20', 'V25', 'V28', 'V29', 'V30', 
       'vehc_MO', 'vehc_RETOP', 'vehc_SC', 'vehc_TL', 'emp_PENS', 'emp_SAL',
       'emp_SELF', 'emp_STUDENT', 'res_OWNED', 'res_RENT', 'tier_TIER 2',
       'tier_TIER 3', 'tier_TIER 4']



X=os_data_X[feature_cols]
y=os_data_y['V32']

"""## Factor Analysis

## Methods Used

### Recursive Factor Exclusion , Linear Regression , Ridge , Lasso , Random Forest
"""

from sklearn.feature_selection import RFE, f_regression
from sklearn.linear_model import (LinearRegression, Ridge, Lasso)
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor

# Define dictionary to store our rankings
ranks = {}
# Create our function which stores the feature rankings to the ranks dictionary
def ranking(ranks, names, order=1):
    minmax = MinMaxScaler()
    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]
    ranks = map(lambda x: round(x,2), ranks)
    return dict(zip(names, ranks))

# Construct our Linear Regression model
lr = LinearRegression(normalize=True)
lr.fit(X,y)
#stop the search when only the last feature is left
rfe = RFE(lr, n_features_to_select=1, verbose =3 )
rfe.fit(X,y)
ranks["RFE"] = ranking(list(map(float, rfe.ranking_)), feature_cols, order=-1)

# Using Linear Regression
lr = LinearRegression(normalize=True)
lr.fit(X,y)
ranks["LinReg"] = ranking(np.abs(lr.coef_), feature_cols)

# Using Ridge 
ridge = Ridge(alpha = 7)
ridge.fit(X,y)
ranks['Ridge'] = ranking(np.abs(ridge.coef_), feature_cols)

# Using Lasso
lasso = Lasso(alpha=.05)
lasso.fit(X, y)
ranks["Lasso"] = ranking(np.abs(lasso.coef_), feature_cols)

rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)
rf.fit(X,y)
ranks["RF"] = ranking(rf.feature_importances_, feature_cols);

# Create empty dictionary to store the mean value calculated from all the scores
r = {}
for name in feature_cols:
    r[name] = round(np.mean([ranks[method][name] 
                             for method in ranks.keys()]), 2)
 
methods = sorted(ranks.keys())
ranks["Mean"] = r
methods.append("Mean")
 
print("\t                %s" % "\t".join(methods))
for name in feature_cols:
    print("%s        \t       %s" % (name, "\t".join(map(str, 
                         [ranks[method][name] for method in methods]))))

# Put the mean scores into a Pandas dataframe
meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])

# Sort the dataframe
meanplot = meanplot.sort_values('Mean Ranking', ascending=False)

# Let's plot the ranking of the features
sns.factorplot(x="Mean Ranking", y="Feature", data = meanplot, kind="bar", 
               size=17, aspect=1.9, palette='coolwarm')

"""# Factors Exclusion"""



"""## RFE"""

tvs_vars=tvs.columns.values.tolist()
y=['V32']
X=[i for i in tvs_vars if i not in y]
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(random_state=1, solver='newton-cg',
                         multi_class='multinomial',max_iter=1200)
rfe = RFE(logreg, 25)
rfe = rfe.fit(os_data_X, os_data_y.values.ravel())
print(rfe.support_)
print(rfe.ranking_)

feature_cols=['V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V11', 'V12', 'V13', 'V16',
       'V17', 'V18', 'V19', 'V20', 'V25', 'V28', 'V29', 'V30', 
       'vehc_MO', 'vehc_RETOP', 'vehc_SC', 'vehc_TL', 'emp_PENS', 'emp_SAL',
       'emp_SELF', 'emp_STUDENT', 'res_OWNED', 'res_RENT', 'tier_TIER 2',
       'tier_TIER 3', 'tier_TIER 4']

X=os_data_X[feature_cols]
y=os_data_y['V32']

import statsmodels.api as sm
logit_model=sm.Logit(y,X)
result=logit_model.fit(maxiter=150)
print(result.summary2())

"""### Factors Excluded ----   V6 , V7 , V8 , V25 , Vehc_Retop"""

feature_cols=['V2', 'V3','V4', 'V5',  'V11','V12', 'V13', 'V16',
       'V17', 'V19', 'V20', 'V28', 'V29', 'V30', 
       'vehc_MO', 'vehc_SC', 'vehc_TL', 'emp_PENS', 'emp_SAL',
       'emp_SELF', 'emp_STUDENT', 'res_OWNED', 'res_RENT', 'tier_TIER 2',
       'tier_TIER 3', 'tier_TIER 4']

X=os_data_X[feature_cols]
y=os_data_y['V32']

import statsmodels.api as sm
logit_model=sm.Logit(y,X)
result=logit_model.fit(maxiter=150)
print(result.summary2())

"""# Logistic R"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix,accuracy_score

X= preprocessing.StandardScaler().fit(X).transform(X)
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)

# instantiate the model (using the default parameters)
logreg = LogisticRegression(random_state=1, solver='lbfgs',
                         multi_class='multinomial',max_iter=1200000)

# fit the model with data
logreg.fit(x_train,y_train)

#
y_pred=logreg.predict(x_test)

print(logreg.coef_)
print(logreg.intercept_)

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="viridis" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print(classification_report(y_test, y_pred))

y_pred = logreg.predict(x_test)
print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

y_pred_proba = logreg.predict_proba(x_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

print("Area under curve : ", auc)

"""# K Neighbour Classifier"""

from sklearn.metrics import jaccard_similarity_score
from sklearn.metrics import jaccard_score
from sklearn.metrics import f1_score
from sklearn.metrics import log_loss
from sklearn.model_selection import cross_val_score

trainScores={}

from sklearn.neighbors import KNeighborsClassifier

bestScore=0.0
accList=[]

for k in range(3,12):
    
    clf_knn = KNeighborsClassifier(n_neighbors=k,algorithm='auto')
    
    # using 10 fold cross validation for scoring the classifier's accuracy
    scores = cross_val_score(clf_knn, x_train, y_train, cv=10)
    score=scores.mean()
    accList.append(score)
    
    if score > bestScore:
        bestScore=score
        best_clf=clf_knn
        bestK=k
        
print("Best K is :",bestK,"| Cross validation Accuracy :",bestScore)
clf_knn=best_clf

plt.plot(range(3,12),accList)
plt.xlabel('K')
plt.ylabel('CV Accuracy')
plt.show()

clf_knn.fit(x_train,y_train)
y_pred=best_clf.predict(x_train)

trainScores['KNN-jaccard']=jaccard_score(y_train, y_pred)
trainScores['KNN-f1-score']=f1_score(y_train, y_pred, average='weighted')

trainScores

"""# Decision Tree"""

from sklearn import tree

clf_tree = tree.DecisionTreeClassifier()
clf_tree = clf_tree.fit(x_train, y_train)

y_pred=clf_tree.predict(x_train)

trainScores['Tree-jaccard']=jaccard_score(y_train, y_pred)
trainScores['Tree-f1-score']=f1_score(y_train, y_pred, average='weighted')

trainScores

"""##  *******   Decision tree graph (Use if needed, heavy lag)  ***************

!pip install graphviz
!pip install pydotplus
import graphviz 
import pydotplus

dot_data = tree.export_graphviz(clf_tree, out_file=None, 
                     feature_names=['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Flight Distance',
       'Seat comfort', 'Departure/Arrival time convenient', 'Food and drink',
       'Gate location', 'Inflight wifi service', 'Inflight entertainment',
       'Online support', 'Ease of Online booking', 'On-board service',
       'Leg room service', 'Baggage handling', 'Checkin service',
       'Cleanliness', 'Online boarding', 'Departure Delay in Minutes',
       'Arrival Delay in Minutes', 'class_Eco', 'class_Eco Plus'],  
                     class_names='satisfaction',  
                     filled=True, rounded=True,  
                     special_characters=True) 

graph = pydotplus.graph_from_dot_data(dot_data)
graph.set_size('"16,16!"')
gvz_graph = graphviz.Source(graph.to_string())

gvz_graph

# Support vector Machine (SVM)
"""

y_train=y_train.astype(float)

from sklearn import svm

clf_svm = svm.LinearSVC(random_state=7,max_iter=120000)
clf_svm.fit(x_train, y_train)  

y_pred=clf_svm.predict(x_train)

trainScores['SVM-jaccard']=jaccard_score(y_train, y_pred)
trainScores['SVM-f1-score']=f1_score(y_train, y_pred, average='weighted')

"""trainScores

# LogReg 2
"""

from sklearn.linear_model import LogisticRegression

clf_log = LogisticRegression(random_state=1, solver='newton-cg',
                         multi_class='multinomial')
clf_log.fit(x_train, y_train)

y_pred=clf_log.predict(x_train)
y_proba=clf_log.predict_proba(x_train)

trainScores['LogReg-jaccard']=jaccard_score(y_train, y_pred)
trainScores['LogReg-f1-score']=f1_score(y_train, y_pred, average='weighted')  
trainScores['LogReg-logLoss']=log_loss(y_train, y_proba)

trainScores

"""# Test Scores"""

testScores={}

"""### KNN Test"""

knn_pred=clf_knn.predict(x_test)
testScores['KNN-jaccard']=jaccard_score(y_test, knn_pred)
testScores['KNN-f1-score']=f1_score(y_test, knn_pred, average='weighted')

"""### Decision Tree Test"""

tree_pred=clf_tree.predict(x_test)
testScores['Tree-jaccard']=jaccard_score(y_test, tree_pred)
testScores['Tree-f1-score']=f1_score(y_test, tree_pred, average='weighted')

"""### SVM test"""

svm_pred=clf_svm.predict(x_test)
testScores['SVM-jaccard']=jaccard_score(y_test, svm_pred)
testScores['SVM-f1-score']=f1_score(y_test, svm_pred, average='weighted')

"""### LogReg Test"""

log_pred=clf_log.predict(x_test)
proba=clf_log.predict_proba(x_test)
testScores['LogReg-jaccard']=jaccard_score(y_test, log_pred)
testScores['LogReg-f1-score']=f1_score(y_test, log_pred, average='weighted')  
testScores['LogReg-logLoss']=log_loss(y_test, proba)

testScores

"""# Test Scores Comparison"""

Jaccard = [0.9089089696161077,0.9364205256570713,0.7867217468279728,0.792161029455168]
F1_score = [0.9513002956680857,0.9670732838287489,0.8828464870716576,0.8858709319099023]
LogLoss = ['NA','NA','NA',0.2832133118614762]

    
df = {'Algorithm': ['KNN', 'Decision Tree', 'SVM', 'Logistic Regression'], \
     'Jaccard': Jaccard, 'F1-score': F1_score, 'LogLoss': LogLoss}

Report = pd.DataFrame(data=df, columns=['Algorithm', 'Jaccard', 'F1-score', 'LogLoss'], index=None)
Report

